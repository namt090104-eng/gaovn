import streamlit as st
import pickle
import numpy as np
import pandas as pd 

# ==========================================================
# C·∫§U H√åNH C·ªêT L√ïI (C·∫¶N THAY ƒê·ªîI THEO D·ª∞ √ÅN C·ª¶A B·∫†N)
# ==========================================================
# Ghi ch√∫: C√°c file .pkl ph·∫£i ƒë∆∞·ª£c ƒë·∫∑t c√πng th∆∞ m·ª•c v·ªõi file app.py n√†y
MODEL_PATH = 'random_forest_model.pkl'  # T√™n file m√¥ h√¨nh RF ƒë√£ l∆∞u
SCALER_PATH = 'scaler.pkl'            # T√™n file StandardScaler ƒë√£ l∆∞u
PCA_PATH = 'pca.pkl'                  # T√™n file PCA ƒë√£ l∆∞u

# T√™n c√°c l·ªõp g·∫°o (C·∫ßn kh·ªõp ch√≠nh x√°c v·ªõi th·ª© t·ª± khi hu·∫•n luy·ªán m√¥ h√¨nh)
CLASS_NAMES = [
    'Arborio (G·∫°o Tr√≤n)', 
    'Basmati (G·∫°o Thon D√†i)', 
    'Ipsala', 
    'Jasmine (G·∫°o Th∆°m)', 
    'Karacadag'
]

# T√™n c√°c ƒë·∫∑c tr∆∞ng g·ªëc (PH·∫¢I KH·ªöP V·ªöI ƒê·∫∂C TR∆ØNG ƒê·∫¶U V√ÄO C·ª¶A SCALER/PCA)
FEATURE_NAMES = [
    'Area (Di·ªán t√≠ch)', 
    'Perimeter (Chu vi)', 
    'MajorAxisLength (Chi·ªÅu d√†i tr·ª•c ch√≠nh)', 
    'MinorAxisLength (Chi·ªÅu d√†i tr·ª•c ph·ª•)',    
    'Eccentricity (ƒê·ªô l·ªách t√¢m)', 
    'ConvexArea (Di·ªán t√≠ch l·ªìi)', 
    'EquivalentDiameter (ƒê∆∞·ªùng k√≠nh t∆∞∆°ng ƒë∆∞∆°ng)'
]

# Gi√° tr·ªã m·∫∑c ƒë·ªãnh cho √¥ nh·∫≠p li·ªáu (C√≥ th·ªÉ l·∫•y trung b√¨nh c·ªßa t·∫≠p d·ªØ li·ªáu)
DEFAULT_FEATURE_VALUES = [7000, 350, 100, 80, 0.7, 7050, 95] 

# Gi√° tr·ªã t·ªëi ƒëa gi·∫£ ƒë·ªãnh cho thanh tr∆∞·ª£t
MAX_FEATURE_VALUES = [15000, 800, 250, 150, 1.0, 15500, 180]
# ==========================================================


@st.cache_resource
def load_rf_components():
    """T·∫£i m√¥ h√¨nh Random Forest, Scaler v√† PCA t·ª´ file .pkl."""
    st.info("ƒêang t·∫£i c√°c th√†nh ph·∫ßn m√¥ h√¨nh (Model, Scaler, PCA)...")
    try:
        with open(MODEL_PATH, 'rb') as f:
            model = pickle.load(f)
        with open(SCALER_PATH, 'rb') as f:
            scaler = pickle.load(f)
        with open(PCA_PATH, 'rb') as f:
            pca = pickle.load(f)
        st.success("T·∫£i m√¥ h√¨nh th√†nh c√¥ng!")
        return model, scaler, pca
    except FileNotFoundError as e:
        st.error(f"L·ªói t·∫£i file: Vui l√≤ng ki·ªÉm tra c√°c file .pkl ({e.filename}) ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t c√πng th∆∞ m·ª•c v·ªõi file Python n√†y ch∆∞a.")
        # D·ª´ng ·ª©ng d·ª•ng n·∫øu kh√¥ng t√¨m th·∫•y file
        st.stop() 
    except Exception as e:
        st.error(f"L·ªói t·∫£i ho·∫∑c gi·∫£i n√©n m√¥ h√¨nh: {e}")
        st.stop()

def predict_features(input_data, model, scaler, pca, class_names):
    """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng v√† d·ª± ƒëo√°n."""
    try:
        # 1. Chuy·ªÉn ƒë·ªïi th√†nh m·∫£ng numpy 2D (1 m·∫´u, N ƒë·∫∑c tr∆∞ng)
        features = np.array(input_data).reshape(1, -1)
        
        # 2. Ti·ªÅn x·ª≠ l√Ω (Ph·∫£i theo ƒë√∫ng th·ª© t·ª±: Scaling -> PCA)
        features_scaled = scaler.transform(features)
        features_pca = pca.transform(features_scaled)
        
        # 3. D·ª± ƒëo√°n x√°c su·∫•t
        predictions = model.predict_proba(features_pca)[0] # L·∫•y m·∫£ng x√°c su·∫•t 1D
        
        # L·∫•y top 3 d·ª± ƒëo√°n
        top_k_indices = np.argsort(predictions)[::-1]
        
        # T·∫°o DataFrame cho k·∫øt qu·∫£ chi ti·∫øt
        results = pd.DataFrame({
            'Lo·∫°i G·∫°o': [class_names[i] for i in top_k_indices],
            'X√°c su·∫•t': [predictions[i] for i in top_k_indices]
        })
        results['X√°c su·∫•t'] = results['X√°c su·∫•t'].apply(lambda x: f"{x:.2%}")
        
        predicted_class_index = top_k_indices[0]
        confidence = predictions[predicted_class_index]
        
        return class_names[predicted_class_index], confidence, results

    except ValueError as e:
        st.error(f"L·ªói ƒë·ªãnh d·∫°ng d·ªØ li·ªáu: S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o kh√¥ng kh·ªõp v·ªõi m√¥ h√¨nh. {e}")
        return "L·ªói x·ª≠ l√Ω", 0.0, pd.DataFrame()
    except Exception as e:
        st.error(f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n (PCA/Model): {e}")
        return "L·ªói x·ª≠ l√Ω", 0.0, pd.DataFrame()


# ==========================================================
# LOGIC ·ª®NG D·ª§NG CH√çNH
# ==========================================================
model, scaler, pca = load_rf_components()

st.set_page_config(page_title="Ph√¢n Lo·∫°i G·∫°o Random Forest", layout="wide")

st.title("üåæ ·ª®ng D·ª•ng Ph√¢n Bi·ªát Lo·∫°i G·∫°o (Random Forest)")
st.markdown(f"**M√¥ h√¨nh:** Random Forest | **ƒê·∫∑c tr∆∞ng:** {len(FEATURE_NAMES)} ƒë·∫∑c tr∆∞ng h√¨nh th√°i ({pca.n_components_} th√†nh ph·∫ßn ch√≠nh)")
st.markdown("---")


# -----------------
# 1. Giao di·ªán Nh·∫≠p li·ªáu (Sidebar)
# -----------------
with st.sidebar:
    st.header("1. Nh·∫≠p ƒê·∫∑c tr∆∞ng H·∫°t G·∫°o")
    st.info("S·ª≠ d·ª•ng c√°c thanh tr∆∞·ª£t b√™n d∆∞·ªõi ƒë·ªÉ nh·∫≠p c√°c gi√° tr·ªã ƒëo ƒë∆∞·ª£c c·ªßa h·∫°t g·∫°o m·ªõi.")
    
    input_data = []
    
    # T·∫°o √¥ nh·∫≠p li·ªáu cho t·ª´ng ƒë·∫∑c tr∆∞ng
    for i, feature in enumerate(FEATURE_NAMES):
        # Thi·∫øt l·∫≠p gi·ªõi h·∫°n min/max d·ª±a tr√™n c·∫•u h√¨nh
        min_val = 0.0
        max_val = MAX_FEATURE_VALUES[i] if i < len(MAX_FEATURE_VALUES) else 1000
        default_val = DEFAULT_FEATURE_VALUES[i] if i < len(DEFAULT_FEATURE_VALUES) else 0

        val = st.slider(
            f"**{i+1}. {feature}**", 
            min_value=min_val, 
            max_value=max_val,
            value=default_val,
            step=0.01 if max_val <= 1.0 else 1.0,
            format="%.2f"
        )
        input_data.append(val)

# -----------------
# 2. N√∫t D·ª± ƒëo√°n v√† Hi·ªÉn th·ªã K·∫øt qu·∫£
# -----------------
st.subheader("2. K·∫øt qu·∫£ Ph√¢n lo·∫°i:")

if st.sidebar.button('üöÄ Ph√¢n Lo·∫°i H·∫°t G·∫°o', type="primary", use_container_width=True):
    
    if len(input_data) != len(FEATURE_NAMES):
        st.error(f"L·ªói: S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o ({len(input_data)}) kh√¥ng kh·ªõp v·ªõi s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng m√¥ h√¨nh y√™u c·∫ßu ({len(FEATURE_NAMES)}).")
    else:
        with st.spinner('ƒêang ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† d·ª± ƒëo√°n...'):
            
            predicted_name, confidence, results_df = predict_features(
                input_data, model, scaler, pca, CLASS_NAMES
            )
            
            if predicted_name != "L·ªói x·ª≠ l√Ω":
                
                # Chia c·ªôt hi·ªÉn th·ªã k·∫øt qu·∫£ ch√≠nh
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.metric(
                        label="Lo·∫°i G·∫°o ƒë∆∞·ª£c d·ª± ƒëo√°n", 
                        value=predicted_name, 
                        delta=f"ƒê·ªô tin c·∫≠y: {confidence:.2%}"
                    )
                    
                with col2:
                    st.info(f"K·∫øt qu·∫£ n√†y ƒë∆∞·ª£c d·ª± ƒëo√°n v·ªõi ƒë·ªô tin c·∫≠y **{confidence:.2%}** l√† lo·∫°i **{predicted_name}**.")
                    
                st.markdown("---")
                
                # HI·ªÇN TH·ªä C√ÅC K·∫æT QU·∫¢ X√ÅC SU·∫§T CAO KH√ÅC
                st.subheader("Ph√¢n t√≠ch X√°c su·∫•t Chi ti·∫øt:")
                
                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì c·ªôt cho x√°c su·∫•t
                st.bar_chart(results_df.set_index('Lo·∫°i G·∫°o')['X√°c su·∫•t'].str.replace('%', '').astype(float))
                
                # Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
                st.dataframe(results_df, hide_index=True, use_container_width=True)
                
st.info("üí° H∆∞·ªõng d·∫´n: Nh·∫≠p c√°c ƒë·∫∑c tr∆∞ng ·ªü thanh b√™n tr√°i v√† nh·∫•n n√∫t 'Ph√¢n Lo·∫°i H·∫°t G·∫°o' ƒë·ªÉ xem k·∫øt qu·∫£ d·ª± ƒëo√°n.")
